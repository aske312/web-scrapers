# web-scrapers
***
### ENG information
###### Sites: app2top.ru
* #### ___app2top_articles.py___
Collects the titles of articles and links to the resource given by the search 
query, taking into account the pagination of the site.
The value to be supplied is "My.com", "Google" or whatever.
We get lists with found articles, as well as links to the articles themselves.
They use the request and beautifulsoup4 libraries to work.
  > parser = ParserApp2top() 
  
  > parser.run(pattern='My.Com')

###### Sites: gazeta.ru
* #### ___readability.py___
  

###### Sites: finance.yahoo.com
* #### ___apiYfinance.py___
    

* #### ___scrYfinance.py___
    

###### Sites: example.com
* #### ___none.py___

***
### RUS information
###### Sites: app2top.ru
* #### ___app2top_articles.py___
Собирает заголовки статей и ссылки на ресурс, выдаваемые поисковым запросом, 
с учетом пагинации сайта.
Подаваемое значение 'My.com', 'Google' или что то своё. 
Получаем списоки с найдеными статьями а так же ссылки на сами статьи.
Используют для работы библиотеки request и beautifulsoup4.
  > parser = ParserApp2top()
  
  > parser.run(pattern='My.Com')

###### Sites: gazeta.ru
* #### ___readability.py___
  

###### Sites: finance.yahoo.com
* #### ___apiYfinance.py___
    

* #### ___scrYfinance.py___
    

###### Sites: example.com
* #### ___none.py___
    
